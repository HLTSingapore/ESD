<!doctype html>
<html>

<head>
  <title>Emotional Voice Conversion: Theory, Databases and ESD</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <style>
    .menu-index {
      color: rgb(255, 255, 255) !important;
      opacity: 1 !important;
      font-weight: 700 !important;
    }
  </style>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <!-------------------------------------------------------------------------------------------->
        <!--Start Intro-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text text-large">
              <p <a target="_blank" href="javascript:void(0)"><a href="https://scholar.google.com/citations?user=I3cMPkwAAAAJ&hl=en&oi=ao">Kun Zhou</a></a>,
              <a target="_blank" href="javascript:void(0)"><a href="https://scholar.google.com/citations?user=inTpYLkAAAAJ&hl=en">Berrak Sisman</a></a>,
              <a target="_blank" href="javascript:void(0)"><a href="https://scholar.google.com/citations?user=B2t0J-IAAAAJ&hl=en">Rui Liu</a></a>,
              <a target="_blank" href="javascript:void(0)"><a href="https://scholar.google.com.sg/citations?user=z8_x7C8AAAAJ&hl=en&oi=ao">Haizhou Li</a></a><br></p>
              <a target="_blank" href="javascript:void(0)">Department of Electrical and Computer Engineering, National University of Singapore, Singapore</a>
              <a target="_blank" href="javascript:void(0)">Information Systems Technology and Design Pillar, Singapore University of Technology and Design, Singapore</a>
            </p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text add-top-margin">
             In this project, we first provide a review of the state-of-the-art emotional voice conversion research, and the existing emotional speech databases. We then motivate the development of a novel emotional speech database (ESD) that addresses the increasing research need. The ESD database is now made available by National University of Singapore (NUS) and Singapore University of Technology and Design (SUTD). The ESD  database consists of 350 parallel utterances spoken by 10 native English and 10 native Mandarin speakers and covers 5 emotion classes (neutral, happiness, anger, sadness and surprise). More than 29 hours of speech data were recorded in controlled acoustic environment. Thus it is suitable for multi-speaker and cross-lingual emotional voice conversion studies. 
             As the case studies, we report experiments of several state-of-the-art emotional voice conversion systems on the ESD database. We also provides a reference study on ESD in conjunction with its release. 
             
              
            </p>
          </div>
        </div>       
        <!--End Intro-->
        <!-------------------------------------------------------------------------------------------->
        <!--Start Text Only-->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Applications</h2>
            <hr>
            <p class="text">
              <ul>
                <li>Emotional voice conversion (mono-lingual & cross-lingual, speaker-dependent & speaker-independent)</li>
                <li>Voice conversion (mono-lingual & cross-lingual)</li>
                <li>Emotional Text-to-Speech</li>
                <li>Expressive Text-to-Speech</li>
              </ul>
            </p>
            </h2>
          </div>
        </div>
         
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Introduction</h2>
            <hr>
    Emotional voice conversion is a voice conversion technique that aims to convert the emotional state of the speech from source to target, while preserving the linguistic information and speaker identity.

            <img class="image" src="img/img3.png">
            </h2>
          </div>
        </div>
        <!-------------------------------------------------------------------------------------------->
        <div class="flex-row">
          <div class="flex-item flex-column">
            <h2 class="add-top-margin">Details of the ESD database</h2>
            <hr>
            <img class="image" src="img/pic1.png">
            </h2>
          </div>
        </div>

         <div class="flex-item flex-column">
          <h2 class="add-top-margin">Organization</h2>  
           <hr>
          <img class="image" src="img/pic3.png">
          </h2>
        </div>

        <div class="flex-row">
        <div class="flex-item flex-column">
        <h2 class="add-top-margin">Reference</h2>
        <hr>

 Please cite the following paper if you use this database:
        <br>
 Kun Zhou, Berrak Sisman, Rui Liu and Haizhou Li, "Seen and unseen emotional style transfer for voice conversion with a new emotional speech dataset" ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)

        </h2>
        </div>

      </div>
    </div>
  </div>
</body>

</html>
